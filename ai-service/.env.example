# Server Configuration
PORT=5000
NODE_ENV="development"

# AI Services
OPENAI_API_KEY="your-openai-api-key"
ANTHROPIC_API_KEY="your-anthropic-api-key"
GEMINI_API_KEY="your-gemini-api-key"

# AI Models
OPENAI_MODEL="gpt-4-turbo-preview"
ANTHROPIC_MODEL="claude-3-sonnet-20240229"
GEMINI_MODEL="gemini-pro"

# AI Provider Configuration
DEFAULT_AI_PROVIDER="claude"
OPENAI_MAX_RETRIES=3
ANTHROPIC_MAX_RETRIES=3
GEMINI_MAX_RETRIES=3
OPENAI_TIMEOUT=30000
ANTHROPIC_TIMEOUT=30000
GEMINI_TIMEOUT=30000

# MCP Server Integration
MCP_SERVER_URL="http://localhost:3001"
MCP_SERVER_TIMEOUT=30000
MCP_SERVER_RETRIES=3

# Backend API
BACKEND_URL="http://localhost:4000"

# Redis for caching AI responses
REDIS_URL="redis://localhost:6379"
CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=50

# CORS
CORS_ORIGIN="http://localhost:4000"

# Logging
LOG_LEVEL="info"

# Queue Configuration (for background AI processing)
QUEUE_REDIS_URL="redis://localhost:6379"
QUEUE_CONCURRENCY=3