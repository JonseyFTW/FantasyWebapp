# Production Environment Template for Railway AI Service
# Copy these variables to your Railway service environment variables

# Server Configuration
PORT=${{PORT}}
NODE_ENV=production

# AI Provider API Keys (configure at least one)
OPENAI_API_KEY=${{OPENAI_API_KEY}}
ANTHROPIC_API_KEY=${{ANTHROPIC_API_KEY}}
GEMINI_API_KEY=${{GEMINI_API_KEY}}

# AI Models Configuration
OPENAI_MODEL=gpt-4-turbo-preview
ANTHROPIC_MODEL=claude-3-sonnet-20240229
GEMINI_MODEL=gemini-pro

# AI Provider Configuration
DEFAULT_AI_PROVIDER=claude
OPENAI_MAX_RETRIES=3
ANTHROPIC_MAX_RETRIES=3
GEMINI_MAX_RETRIES=3
OPENAI_TIMEOUT=30000
ANTHROPIC_TIMEOUT=30000
GEMINI_TIMEOUT=30000

# MCP Server Integration
MCP_SERVER_URL=${{MCP_SERVER_URL}}
MCP_SERVER_TIMEOUT=30000
MCP_SERVER_RETRIES=3

# Backend API Integration
BACKEND_URL=${{BACKEND_SERVICE_URL}}

# Redis Caching
REDIS_URL=${{REDIS_URL}}
CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=50

# CORS Configuration
CORS_ORIGIN=${{BACKEND_SERVICE_URL}},${{FRONTEND_URL}}

# Logging
LOG_LEVEL=info

# Queue Configuration
QUEUE_REDIS_URL=${{REDIS_URL}}
QUEUE_CONCURRENCY=3